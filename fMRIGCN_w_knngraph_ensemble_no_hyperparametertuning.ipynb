{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcETEs3sciNg",
        "outputId": "3b322303-d185-4659-bf1c-bfd769450833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p3F7GLjJWqKE",
        "outputId": "eee414e8-7937-4643-d73a-b0395ff5880f"
      },
      "outputs": [],
      "source": [
        "#@title Downloading PyTorch Geometric\n",
        "\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "print(f'â–¶ï¸Ž Successfully installed PyTorch {TORCH} with CUDA {CUDA}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmlvXg84ZVGx",
        "outputId": "1d34213a-d274-4f65-f32c-814083dc4256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â–¶ï¸Ž Finished Environment Setting\n"
          ]
        }
      ],
      "source": [
        "# 3. Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Dataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "print(\"â–¶ï¸Ž Finished Environment Setting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9vftGDAdBTh",
        "outputId": "df35193d-352b-464c-c171-d4ae26d108da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-FK0QcBZYM1",
        "outputId": "da39ed20-f430-47ef-b1e4-ac2d144de0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â–¶ï¸Ž Finished Drive Mount and Directory Settings.\n"
          ]
        }
      ],
      "source": [
        "# Set Data Directories \n",
        "\n",
        "\n",
        "#These directories shoule be modified according to your file structure \n",
        "# Schaefer Atlas\n",
        "CN_FC_SCHAEFER_DIR = Path('../CN_conn_roi_data/schaefer/fc')\n",
        "CN_ROI_SCHAEFER_DIR = Path('../CN_conn_roi_data/schaefer/roi')\n",
        "AD_FC_SCHAEFER_DIR = Path('..AD_conn_roi_data/schaefer/fc')\n",
        "AD_ROI_SCHAEFER_DIR = Path('../AD_conn_roi_data/schaefer/roi')\n",
        "\n",
        "# AAL Atlas\n",
        "CN_FC_AAL_DIR = Path('../CN_conn_roi_data/aal/fc')\n",
        "CN_ROI_AAL_DIR = Path('../CN_conn_roi_data/aal/roi')\n",
        "AD_FC_AAL_DIR = Path('../AD_conn_roi_data/aal/fc')\n",
        "AD_ROI_AAL_DIR = Path('../AD_conn_roi_data/aal/roi')\n",
        "\n",
        "\n",
        "# Set Hyperparameters \n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 32\n",
        "INNER_NUM_EPOCHS = 30\n",
        "OUTER_NUM_EPOCHS = 100\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "print(\"â–¶ï¸Ž Finished Drive Mount and Directory Settings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc3e4539"
      },
      "outputs": [],
      "source": [
        "import os # Import os for path joining\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "\n",
        "class fMRIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Processing fMRI Dataset for single Atlas (AAL or Schaefer) using KNN graph.\n",
        "    \"\"\"\n",
        "    def __init__(self, root, cn_fc_dir, cn_roi_dir, ad_fc_dir, ad_roi_dir, k_neighbors=10, transform=None, pre_transform=None):\n",
        "        self.cn_fc_dir = cn_fc_dir\n",
        "        self.cn_roi_dir = cn_roi_dir\n",
        "        self.ad_fc_dir = ad_fc_dir\n",
        "        self.ad_roi_dir = ad_roi_dir\n",
        "        self.k_neighbors = k_neighbors \n",
        "\n",
        "\n",
        "        if 'schaefer' in str(cn_fc_dir).lower():\n",
        "            self.atlas_type = 'schaefer'\n",
        "        elif 'aal' in str(cn_fc_dir).lower():\n",
        "            self.atlas_type = 'aal'\n",
        "        else:\n",
        "            self.atlas_type = 'unknown'\n",
        "            print(f\"Warning: Could not determine atlas type from directory names: {cn_fc_dir}\")\n",
        "\n",
        "\n",
        "        self.ad_subjects = [f.stem.split('_')[0] for f in self.ad_fc_dir.glob('*.csv')]\n",
        "        self.cn_subjects = [f.stem.split('_')[0] for f in self.cn_fc_dir.glob('*.csv')]\n",
        "        self.all_subjects = sorted(list(set(self.ad_subjects + self.cn_subjects)))\n",
        "\n",
        "\n",
        "        valid_subjects = []\n",
        "        for sub in self.all_subjects:\n",
        "            expected_fc_path = (self.ad_fc_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_connectivity_matrix.csv\") if sub in self.ad_subjects else (self.cn_fc_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_connectivity_matrix.csv\")\n",
        "            expected_roi_path = (self.ad_roi_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_roi_timeseries.csv\") if sub in self.ad_subjects else (self.cn_roi_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_roi_timeseries.csv\")\n",
        "\n",
        "\n",
        "            fc_found = expected_fc_path.exists() or list(self.ad_fc_dir.glob(f\"{sub}*connectivity_matrix.csv\")) or list(self.cn_fc_dir.glob(f\"{sub}*connectivity_matrix.csv\"))\n",
        "            roi_found = expected_roi_path.exists() or list(self.ad_roi_dir.glob(f\"{sub}*roi_timeseries.csv\")) or list(self.cn_roi_dir.glob(f\"{sub}*roi_timeseries.csv\"))\n",
        "\n",
        "\n",
        "            if fc_found and roi_found:\n",
        "                valid_subjects.append(sub)\n",
        "            else:\n",
        "                if not fc_found and not roi_found:\n",
        "                    print(f\"Warning: FC and ROI data missing for subject {sub}. Skipping.\")\n",
        "                elif not fc_found:\n",
        "                    print(f\"Warning: FC data missing for subject {sub}. Skipping.\")\n",
        "                elif not roi_found:\n",
        "                     print(f\"Warning: ROI data missing for subject {sub}. Skipping.\")\n",
        "\n",
        "\n",
        "        self.all_subjects = valid_subjects\n",
        "        self.ad_subjects = [sub for sub in self.all_subjects if sub in self.ad_subjects]\n",
        "        self.cn_subjects = [sub for sub in self.all_subjects if sub in self.cn_subjects]\n",
        "\n",
        "        print(f\"Initialized dataset with {len(self.all_subjects)} valid subjects.\")\n",
        "\n",
        "\n",
        "        super(fMRIDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "         cn_files = [f.name for f in self.cn_fc_dir.glob('*.csv')] + [f.name for f in self.cn_roi_dir.glob('*.csv')]\n",
        "         ad_files = [f.name for f in self.ad_fc_dir.glob('*.csv')] + [f.name for f in self.ad_roi_dir.glob('*.csv')]\n",
        "         return list(set(cn_files + ad_files)) \n",
        "\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # Define the names of the processed data files\n",
        "        return [f'data_{i}.pt' for i in range(len(self.all_subjects))]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        print(f\"Processing {len(self.all_subjects)} subjects...\")\n",
        "        for idx, subject_id in enumerate(self.all_subjects):\n",
        "            print(f\"Processing subject {subject_id} ({idx + 1}/{len(self.all_subjects)})...\")\n",
        "\n",
        "            if subject_id in self.ad_subjects:\n",
        "                label = 1\n",
        "                fc_dir, roi_dir = self.ad_fc_dir, self.ad_roi_dir\n",
        "            else:\n",
        "                label = 0\n",
        "                fc_dir, roi_dir = self.cn_fc_dir, self.cn_roi_dir\n",
        "\n",
        "            # Find the actual FC and ROI file paths for the subject\n",
        "            fc_path_candidates = list(fc_dir.glob(f\"{subject_id}*connectivity_matrix.csv\"))\n",
        "            roi_path_candidates = list(roi_dir.glob(f\"{subject_id}*roi_timeseries.csv\"))\n",
        "\n",
        "            fc_path = fc_path_candidates[0] if fc_path_candidates else None\n",
        "            roi_path = roi_path_candidates[0] if roi_path_candidates else None\n",
        "\n",
        "\n",
        "            if fc_path is None or roi_path is None:\n",
        "                 print(f\"Error during processing: Data for subject {subject_id} not found at expected paths. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            try:\n",
        "                fc_matrix = pd.read_csv(fc_path, index_col=0).values\n",
        "                roi_data = pd.read_csv(roi_path).values\n",
        "                print(f\"  Successfully loaded data. FC shape: {fc_matrix.shape}, ROI shape: {roi_data.shape}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading files for subject {subject_id}: {e}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Robust ROI Data Transposition Logic \n",
        "            initial_roi_shape = roi_data.shape\n",
        "            expected_nodes = fc_matrix.shape[0]\n",
        "\n",
        "            if initial_roi_shape[0] == expected_nodes:\n",
        "                pass\n",
        "            elif initial_roi_shape[1] == expected_nodes:\n",
        "                roi_data = roi_data.T\n",
        "                print(f\"  Transposed ROI data for subject {subject_id}. Initial shape: {initial_roi_shape}, New shape: {roi_data.shape}\")\n",
        "            else:\n",
        "                print(f\"Warning: ROI data shape mismatch for subject {subject_id}. Expected one dimension to match number of nodes ({expected_nodes}), got shape {initial_roi_shape}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            if roi_data.shape[0] != expected_nodes:\n",
        "                 print(f\"Error: ROI data first dimension still does not match expected nodes after transposition logic for subject {subject_id}. Expected {expected_nodes}, got {roi_data.shape[0]}. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            # Define Node Features (x)\n",
        "            x = torch.tensor(fc_matrix, dtype=torch.float)\n",
        "            num_nodes = x.shape[0]\n",
        "            print(f\"  Node features (x) shape: {x.shape}\")\n",
        "\n",
        "            # KNN Graph Construction and Edge Weighting \n",
        "            edge_index = []\n",
        "            edge_attr = []\n",
        "\n",
        "            # NearestNeighbors to find k_neighbors for each node\n",
        "            nn = NearestNeighbors(n_neighbors=self.k_neighbors + 1, metric='euclidean')\n",
        "            nn.fit(x.cpu().numpy()) \n",
        "\n",
        "            # Find neighbors and distances\n",
        "            # distances, indices shape: (num_nodes, k_neighbors + 1)\n",
        "            distances, indices = nn.kneighbors(x.cpu().numpy())\n",
        "\n",
        "            for i in range(num_nodes):\n",
        "                for j in range(1, self.k_neighbors + 1): \n",
        "                    neighbor_index = indices[i, j]\n",
        "                    distance = distances[i, j]\n",
        "\n",
        "                    edge_index.append([i, neighbor_index])\n",
        "                    weight = 1.0 / (distance + 1e-8)\n",
        "                    edge_attr.append([weight])\n",
        "\n",
        "\n",
        "            # Convert lists to tensors\n",
        "            if not edge_index:\n",
        "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "                edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
        "            else:\n",
        "                edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "                edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "            # Ensure edge_index has correct shape (2, num_edges)\n",
        "            if edge_index.ndim != 2 or edge_index.shape[0] != 2:\n",
        "                 print(f\"Error creating edge_index for subject {subject_id}. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            # Create PyTorch Geometric Data object\n",
        "            data = Data(x=x,\n",
        "                        edge_index=edge_index,\n",
        "                        edge_attr=edge_attr, \n",
        "                        y=torch.tensor([label], dtype=torch.long))\n",
        "\n",
        "            save_path = os.path.join(self.processed_dir, f'data_{idx}.pt')\n",
        "            try:\n",
        "                torch.save(data, save_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving processed data for subject {subject_id} to {save_path}: {e}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "        print(\"Finished processing subjects.\")\n",
        "\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'), weights_only=False)\n",
        "        return data\n",
        "\n",
        "    def len(self) -> int:\n",
        "        \"\"\"Returns the number of data objects stored in the dataset.\"\"\"\n",
        "        return len(self.all_subjects) \n",
        "\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self):\n",
        "        if len(self.processed_file_names) > 0:\n",
        "             try:\n",
        "                 first_processed_file = os.path.join(self.processed_dir, self.processed_file_names[0])\n",
        "                 if os.path.exists(first_processed_file):\n",
        "                     data = torch.load(first_processed_file, weights_only=False)\n",
        "                     return data.x.shape[1] \n",
        "                 else:\n",
        "                     print(f\"Warning: First processed file not found at {first_processed_file}. Cannot determine num_node_features.\")\n",
        "                     return 0\n",
        "             except Exception as e:\n",
        "                 print(f\"Error loading first processed file to determine num_node_features: {e}\")\n",
        "                 return 0\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsW2z5Qqt9-_",
        "outputId": "e92c6be3-bc73-4c7c-fa3b-acd236698087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â–¶ï¸Ž Finished Defining Dataset Class and GCN Model (Modified for weighted edges).\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data \n",
        "import torch\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes, hidden_channels=64):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin1 = Linear(hidden_channels, num_classes)\n",
        "        self.dropout = Dropout(p=DROPOUT_RATE)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Data object contains edge_attr\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        edge_weight = edge_attr.squeeze() if edge_attr is not None else None\n",
        "\n",
        "        x = self.conv1(x, edge_index, edge_weight) \n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight) \n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin1(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "print(\"â–¶ï¸Ž Finished Defining Dataset Class and GCN Model (Modified for weighted edges).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AudyYJ12HAiz",
        "outputId": "23e6b6e3-1711-4b81-acbe-338f8c9bee69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â–¶ï¸Ž Finished Defining Training and Testing Function.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tqdm import tqdm \n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score \n",
        "\n",
        "def train_model(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for data in tqdm(loader, desc=\"Training\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def test_model(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(data.y.cpu().numpy())\n",
        "            all_probs.extend(torch.exp(out).cpu().numpy()) \n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    # Calculate AUC\n",
        "    auc_score = 0 \n",
        "    if len(np.unique(all_labels)) > 1 and np.array(all_probs).shape[1] == 2:\n",
        "        try:\n",
        "            # Get probability of the positive class\n",
        "            probs_positive_class = np.array(all_probs)[:, 1]\n",
        "            auc_score = roc_auc_score(all_labels, probs_positive_class)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate AUC: {e}\")\n",
        "            auc_score = 0\n",
        "\n",
        "    # Calculate Recall for the positive class \n",
        "    recall = 0 \n",
        "    if len(all_labels) > 0 and 1 in all_labels:\n",
        "        try:\n",
        "            recall = recall_score(all_labels, all_preds, pos_label=1)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate Recall: {e}\")\n",
        "            recall = 0\n",
        "\n",
        "\n",
        "    return accuracy, f1, auc_score, recall, all_preds, all_labels, np.array(all_probs)\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, title):\n",
        "    \"\"\"\n",
        "    Visualising Confusion Matrix\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "print(\"â–¶ï¸Ž Finished Defining Training and Testing Function.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-mg1jgHP78",
        "outputId": "cd916b59-3e79-4a6f-9288-4c8908560161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ–¥ï¸ Current Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ðŸ–¥ï¸ Current Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcXXJ1FYeKhb"
      },
      "outputs": [],
      "source": [
        "# --- Model Training  ---\n",
        "def run_training(atlas_name, dataset, num_epochs=100):\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"â–¶ï¸Ž Start Training {atlas_name} Atlas Model ...\")\n",
        "\n",
        "    # Data Splitting\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        np.arange(len(dataset)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=[data.y.item() for data in dataset]\n",
        "    )\n",
        "    train_dataset = dataset[train_idx]\n",
        "    test_dataset = dataset[test_idx]\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialise Model, Optimiser, Loss function\n",
        "    model = GCN(\n",
        "        num_node_features=dataset.num_node_features,\n",
        "        num_classes=dataset.num_classes,\n",
        "        hidden_channels=64\n",
        "    ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training the model\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        loss = train_model(model, train_loader, criterion, optimizer, device)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    # Evaluating the model\n",
        "    test_acc, test_f1, test_auc, test_recall, _, _, _ = test_model(model, test_loader, device) # Capture all returned metrics\n",
        "    print(f\"{atlas_name} Model Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test F1-Score: {test_f1:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test AUC: {test_auc:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test Recall (AD): {test_recall:.4f}\")\n",
        "\n",
        "\n",
        "    # Saving the trained model\n",
        "    model_save_path = f'./{atlas_name}_gcn_model.pth'\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"{atlas_name} model is save in the path: '{model_save_path}'.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return model, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Single Model Cross Validation AAL (without hyperparameter tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bIbT2iLxdvsy",
        "outputId": "0c925ae7-3ec4-4861-cb84-2ad1aa9d7836"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, roc_curve, auc, roc_auc_score, recall_score # Import recall_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting AAL Model Cross-Validation with KNN Graph\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Cross-Validation Setup \n",
        "K_FOLDS = 10\n",
        "NUM_EPOCHS = 30\n",
        "K_NEIGHBORS = 10 # Define K for KNN graph construction\n",
        "\n",
        "# Use a single StratifiedKFold instance to split indices for both datasets\n",
        "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store results for each Fold \n",
        "aal_fold_history = []\n",
        "all_aal_preds = []\n",
        "all_aal_labels = []\n",
        "all_aal_probs = []\n",
        "\n",
        "# Load Full Dataset Info for subject list and labels \n",
        "\n",
        "\n",
        "# AAL Full Dataset Info \n",
        "full_dataset_aal_info = fMRIDataset(\n",
        "    root='./data/aal_full_cv_info',\n",
        "    cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "    ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "    k_neighbors=K_NEIGHBORS\n",
        ")\n",
        "\n",
        "\n",
        "# Use labels from this dataset for stratification\n",
        "dataset_labels = [data.y.item() for data in full_dataset_aal_info]\n",
        "\n",
        "# Store the full subject list for easier file path retrieval\n",
        "full_subject_list = full_dataset_aal_info.all_subjects\n",
        "full_cn_subjects = full_dataset_aal_info.cn_subjects\n",
        "full_ad_subjects = full_dataset_aal_info.ad_subjects\n",
        "\n",
        "\n",
        "# --- 3. Start Cross-Validation Loop ---\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(np.arange(len(full_subject_list)), dataset_labels)):\n",
        "    print(f\"\\n=============== FOLD {fold+1}/{K_FOLDS} ================\")\n",
        "\n",
        "    # Create Fold-specific Datasets and Data Loaders using KNN graph \n",
        "\n",
        "    dataset_aal_fold_knn = fMRIDataset(\n",
        "        root=f'./data/aal_fold_{fold+1}_knn',\n",
        "        cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "        ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "        k_neighbors=K_NEIGHBORS # Pass K for KNN\n",
        "    )\n",
        "    # Create Subset and DataLoader for AAL using the dataset with KNN graph\n",
        "    train_dataset_aal_fold_knn = torch.utils.data.Subset(dataset_aal_fold_knn, train_idx)\n",
        "    test_dataset_aal_fold_knn = torch.utils.data.Subset(dataset_aal_fold_knn, test_idx)\n",
        "    train_loader_aal_knn = DataLoader(train_dataset_aal_fold_knn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader_aal_knn = DataLoader(test_dataset_aal_fold_knn, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "    # Initialise and Train Model within the Fold \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Initialise and Train AAL Model using the KNN graph data loader\n",
        "    print(f\"\\nFold {fold+1}: Training AAL Model with KNN Graph...\")\n",
        "    model_aal_fold = GCN(\n",
        "        # Use num_node_features and num_classes from the fold-specific dataset\n",
        "        num_node_features=dataset_aal_fold_knn.num_node_features,\n",
        "        num_classes=dataset_aal_fold_knn.num_classes\n",
        "    ).to(device)\n",
        "    optimizer_aal = torch.optim.Adam(model_aal_fold.parameters(), lr=LEARNING_RATE)\n",
        "    criterion_aal = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        loss = train_model(model_aal_fold, train_loader_aal_knn, criterion_aal, optimizer_aal, device)\n",
        "        if epoch % 10 == 0: \n",
        "             print(f'  AAL Epoch: {epoch:03d}, Train Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "    # Obtain Prediction Probabilities and Labels on Test Data within the Fold \n",
        "    test_accuracy, test_f1, test_auc, test_recall, preds_aal_test, labels_aal_test, probs_aal_test = test_model(model_aal_fold, test_loader_aal_knn, device)\n",
        "\n",
        "\n",
        "    current_fold_true_labels = np.array(labels_aal_test)\n",
        "\n",
        "    # Calculate AUC for the current fold's test set\n",
        "    fold_auc = 0 \n",
        "    if probs_aal_test is not None and probs_aal_test.shape[1] == 2 and len(current_fold_true_labels) == len(probs_aal_test):\n",
        "        try:\n",
        "            probs_positive_class_fold = probs_aal_test[:, 1]\n",
        "            fold_auc = roc_auc_score(current_fold_true_labels, probs_positive_class_fold)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate AUC for fold {fold+1}: {e}\")\n",
        "            fold_auc = 0 \n",
        "\n",
        "    # Calculate Recall for the positive class (AD, label 1) \n",
        "    fold_recall = 0 \n",
        "    if len(current_fold_true_labels) > 0 and 1 in current_fold_true_labels:\n",
        "        try:\n",
        "            fold_recall = recall_score(current_fold_true_labels, preds_aal_test, pos_label=1)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate Recall for fold {fold+1}: {e}\")\n",
        "            fold_recall = 0\n",
        "\n",
        "\n",
        "    # Evaluate Fold Performance and Collect Results\n",
        "    fold_accuracy = accuracy_score(current_fold_true_labels, preds_aal_test)\n",
        "\n",
        "    aal_fold_history.append({'acc': fold_accuracy, 'auc': fold_auc, 'recall': fold_recall}) \n",
        "    all_aal_preds.extend(preds_aal_test)\n",
        "    all_aal_labels.extend(current_fold_true_labels)\n",
        "    all_aal_probs.extend(probs_aal_test) \n",
        "\n",
        "    print(f\"Fold {fold+1} Test Accuracy: {fold_accuracy:.4f}, AUC: {fold_auc:.4f}, Recall (AD): {fold_recall:.4f}\") \n",
        "\n",
        "    # Memory Cleanup\n",
        "    del model_aal_fold, optimizer_aal, criterion_aal\n",
        "    del train_dataset_aal_fold_knn, test_dataset_aal_fold_knn, train_loader_aal_knn, test_loader_aal_knn\n",
        "    del dataset_aal_fold_knn \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Cross-Validation Complete \n",
        "print(\"\\n=============== Cross-Validation Complete ===============\")\n",
        "\n",
        "# Final Result Analysis \n",
        "if aal_fold_history:\n",
        "    avg_acc = np.mean([f['acc'] for f in aal_fold_history])\n",
        "    avg_auc = np.mean([f['auc'] for f in aal_fold_history]) \n",
        "    avg_recall = np.mean([f['recall'] for f in aal_fold_history])\n",
        "    f1 = f1_score(all_aal_labels, all_aal_preds, average='weighted')\n",
        "\n",
        "    print(f\"\\n{K_FOLDS}-Fold Cross-validation Result (AAL with KNN Graph):\")\n",
        "    print(f\"  - Average Test Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"  - Average Test AUC: {avg_auc:.4f}\") \n",
        "    print(f\"  - Average Test Recall (AD): {avg_recall:.4f}\") \n",
        "    print(f\"  - Average Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # Overall Confusion Matrix \n",
        "    cm = confusion_matrix(all_aal_labels, all_aal_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "    plt.title(f'{K_FOLDS}-Fold Cross-Validation Confusion Matrix (AAL single model with KNN Graph)')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Couldn't execute cross-validation.\")\n",
        "\n",
        "\n",
        "# Classification Report \n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_aal_labels, all_aal_preds, target_names=['CN', 'AD'], digits=4))\n",
        "\n",
        "# =========================================================\n",
        "# --- ROC Curve and AUC Visualization ---\n",
        "# =========================================================\n",
        "\n",
        "all_aal_probs_np = np.array(all_aal_probs)\n",
        "\n",
        "if all_aal_probs_np.ndim > 1 and all_aal_probs_np.shape[1] > 1:\n",
        "    probs_positive_class = all_aal_probs_np[:, 1]\n",
        "else:\n",
        "    print(\"Warning: Unexpected shape for all_aal_probs. Cannot plot ROC curve.\")\n",
        "    probs_positive_class = None\n",
        "\n",
        "if probs_positive_class is not None:\n",
        "    # Ensure labels and probabilities have the same length\n",
        "    if len(all_aal_labels) == len(probs_positive_class):\n",
        "        fpr, tpr, thresholds = roc_curve(all_aal_labels, probs_positive_class)\n",
        "        roc_auc = auc(fpr, tpr) # This is the AUC for the overall collected predictions/probs\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (overall area = {roc_auc:.4f})') # Label as overall AUC\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curve for AAL Model with KNN Graph')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Error: Length of test labels ({len(all_aal_labels)}) does not match length of probabilities ({len(probs_positive_class)}). Cannot plot ROC curve.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Single Model Cross-Validation Schaefer (without hyperparameter tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X5jV4037Xc4L",
        "outputId": "e6408d0a-37db-4a22-916c-e9ee4ae6b42b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from pathlib import Path \n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, roc_curve, auc, roc_auc_score, recall_score # Import recall_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting Schaefer Model Cross-Validation with KNN Graph\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "#Cross-Validation Setup\n",
        "\n",
        "NUM_EPOCHS = 30\n",
        "K_NEIGHBORS = 10 # Define K for KNN graph construction\n",
        "\n",
        "# Use a single StratifiedKFold instance to split indices for both datasets\n",
        "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "schaefer_fold_history = []\n",
        "all_schaefer_preds = []\n",
        "all_schaefer_labels = []\n",
        "all_schaefer_probs = []\n",
        "\n",
        "# Load Full Dataset Info for subject list and labels \n",
        "full_dataset_schaefer_info = fMRIDataset(\n",
        "    root='./data/schaefer_full_cv_info', \n",
        "    ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "    k_neighbors=K_NEIGHBORS \n",
        ")\n",
        "\n",
        "\n",
        "# Use labels from this dataset for stratification\n",
        "dataset_labels = [data.y.item() for data in full_dataset_schaefer_info]\n",
        "\n",
        "# Store the full subject list for easier file path retrieval\n",
        "full_subject_list = full_dataset_schaefer_info.all_subjects\n",
        "full_cn_subjects = full_dataset_schaefer_info.cn_subjects\n",
        "full_ad_subjects = full_dataset_schaefer_info.ad_subjects\n",
        "\n",
        "\n",
        "# Start Cross-Validation Loop \n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(np.arange(len(full_subject_list)), dataset_labels)):\n",
        "    print(f\"\\n=============== FOLD {fold+1}/{K_FOLDS} ================\")\n",
        "\n",
        "    # Create Fold-specific Datasets and Data Loaders using KNN graph \n",
        "\n",
        "    dataset_schaefer_fold_knn = fMRIDataset(\n",
        "        root=f'./data/schaefer_fold_{fold+1}_knn',\n",
        "        cn_fc_dir=CN_FC_SCHAEFER_DIR, cn_roi_dir=CN_ROI_SCHAEFER_DIR,\n",
        "        ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "        k_neighbors=K_NEIGHBORS # Pass K for KNN\n",
        "    )\n",
        "    # Create Subset and DataLoader for Schaefer using the dataset with KNN graph\n",
        "    train_dataset_schaefer_fold_knn = torch.utils.data.Subset(dataset_schaefer_fold_knn, train_idx)\n",
        "    test_dataset_schaefer_fold_knn = torch.utils.data.Subset(dataset_schaefer_fold_knn, test_idx)\n",
        "    train_loader_schaefer_knn = DataLoader(train_dataset_schaefer_fold_knn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader_schaefer_knn = DataLoader(test_dataset_schaefer_fold_knn, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "    # Initialise and Train Model within the Fold ---\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Initialise and Train Schaefer Model using the KNN graph data loader\n",
        "    print(f\"\\nFold {fold+1}: Training Schaefer Model with KNN Graph...\")\n",
        "    model_schaefer_fold = GCN(\n",
        "        # Use num_node_features and num_classes from the fold-specific dataset\n",
        "        num_node_features=dataset_schaefer_fold_knn.num_node_features,\n",
        "        num_classes=dataset_schaefer_fold_knn.num_classes\n",
        "    ).to(device)\n",
        "    optimizer_schaefer = torch.optim.Adam(model_schaefer_fold.parameters(), lr=LEARNING_RATE)\n",
        "    criterion_schaefer = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        loss = train_model(model_schaefer_fold, train_loader_schaefer_knn, criterion_schaefer, optimizer_schaefer, device)\n",
        "        if epoch % 10 == 0: # Reduced print frequency for cleaner output\n",
        "             print(f'  Schaefer Epoch: {epoch:03d}, Train Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "    #  Prediction Probabilities and Labels on Test Data within the Fold \n",
        "    test_accuracy, test_f1, test_auc, test_recall, preds_schaefer_test, labels_schaefer_test, probs_schaefer_test = test_model(model_schaefer_fold, test_loader_schaefer_knn, device)\n",
        "\n",
        "\n",
        "    current_fold_true_labels = np.array(labels_schaefer_test)\n",
        "\n",
        "    # Calculate AUC for the current fold's test set\n",
        "    fold_auc = 0 # Default AUC if calculation fails\n",
        "\n",
        "    if probs_schaefer_test is not None and probs_schaefer_test.shape[1] == 2 and len(current_fold_true_labels) == len(probs_schaefer_test):\n",
        "        try:\n",
        "            # Get probability of the positive class (AD, label 1)\n",
        "            probs_positive_class_fold = probs_schaefer_test[:, 1]\n",
        "            fold_auc = roc_auc_score(current_fold_true_labels, probs_positive_class_fold)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate AUC for fold {fold+1}: {e}\")\n",
        "            fold_auc = 0 \n",
        "\n",
        "    # Calculate Recall for the positive class (AD, label 1) \n",
        "    fold_recall = 0 \n",
        "    if len(current_fold_true_labels) > 0 and 1 in current_fold_true_labels:\n",
        "        try:\n",
        "            fold_recall = recall_score(current_fold_true_labels, preds_schaefer_test, pos_label=1)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate Recall for fold {fold+1}: {e}\")\n",
        "            fold_recall = 0\n",
        "\n",
        "\n",
        "    # Evaluate Fold Performance and Collect Results  ---\n",
        "    fold_accuracy = accuracy_score(current_fold_true_labels, preds_schaefer_test)\n",
        "    # Store accuracy, AUC, and Recall in fold_history\n",
        "    schaefer_fold_history.append({'acc': fold_accuracy, 'auc': fold_auc, 'recall': fold_recall}) # Added recall\n",
        "    all_schaefer_preds.extend(preds_schaefer_test)\n",
        "    all_schaefer_labels.extend(current_fold_true_labels)\n",
        "    all_schaefer_probs.extend(probs_schaefer_test)\n",
        "\n",
        "    print(f\"Fold {fold+1} Test Accuracy: {fold_accuracy:.4f}, AUC: {fold_auc:.4f}, Recall (AD): {fold_recall:.4f}\") # Added recall printout\n",
        "\n",
        "    # Memory Cleanup \n",
        "    del model_schaefer_fold, optimizer_schaefer, criterion_schaefer\n",
        "    # Clean up data loaders and datasets created for this fold\n",
        "    del train_dataset_schaefer_fold_knn, test_dataset_schaefer_fold_knn, train_loader_schaefer_knn, test_loader_schaefer_knn\n",
        "    del dataset_schaefer_fold_knn # Delete the dataset instance\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Cross-Validation Complete \n",
        "print(\"\\n=============== Cross-Validation Complete ===============\")\n",
        "\n",
        "#  Final Result Analysis\n",
        "if schaefer_fold_history:\n",
        "    avg_acc = np.mean([f['acc'] for f in schaefer_fold_history])\n",
        "    avg_auc = np.mean([f['auc'] for f in schaefer_fold_history]) # Calculate average AUC\n",
        "    avg_recall = np.mean([f['recall'] for f in schaefer_fold_history]) # Calculate average Recall\n",
        "    f1 = f1_score(all_schaefer_labels, all_schaefer_preds, average='weighted')\n",
        "\n",
        "    print(f\"\\n{K_FOLDS}-Fold Cross-validation Result (Schaefer with KNN Graph):\")\n",
        "    print(f\"  - Average Test Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"  - Average Test AUC: {avg_auc:.4f}\") # Print average AUC\n",
        "    print(f\"  - Average Test Recall (AD): {avg_recall:.4f}\") # Print average Recall\n",
        "    print(f\"  - Average Test F1-Score: {f1:.4f}\")\n",
        "\n",
        "   \n",
        "    cm = confusion_matrix(all_schaefer_labels, all_schaefer_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "    plt.title(f'{K_FOLDS}-Fold Cross-Validation Confusion Matrix (Schaefer single model with KNN Graph)')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Couldn't execute cross-validation.\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_schaefer_labels, all_schaefer_preds, target_names=['CN', 'AD'], digits=4))\n",
        "\n",
        "# =========================================================\n",
        "# --- ROC Curve and AUC Visualization -----\n",
        "# =========================================================\n",
        "\n",
        "all_schaefer_probs_np = np.array(all_schaefer_probs)\n",
        "\n",
        "if all_schaefer_probs_np.ndim > 1 and all_schaefer_probs_np.shape[1] > 1:\n",
        "    probs_positive_class = all_schaefer_probs_np[:, 1]\n",
        "else:\n",
        "    # Fallback if somehow probs are not in the expected shape (shouldn't happen with log_softmax and exp)\n",
        "    print(\"Warning: Unexpected shape for all_schaefer_probs. Cannot plot ROC curve.\")\n",
        "    probs_positive_class = None\n",
        "\n",
        "if probs_positive_class is not None:\n",
        "    # Ensure labels and probabilities have the same length\n",
        "    if len(all_schaefer_labels) == len(probs_positive_class):\n",
        "        fpr, tpr, thresholds = roc_curve(all_schaefer_labels, probs_positive_class)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curve for Schaefer Model with KNN Graph')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Error: Length of test labels ({len(all_schaefer_labels)}) does not match length of probabilities ({len(probs_positive_class)}). Cannot plot ROC curve.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ensemble the Results from each atlas-based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c953cb7b",
        "outputId": "9b34b6a6-bffe-47b6-a964-f36847279f6d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Performing Hard Voting Ensemble with Tie Based on Recall Weighted Sum\n",
        "# using AAL and Schaefer model predictions and probabilities.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting Hard Voting + Tie Based on Recall Weighted Sum Ensemble\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Load Results and Calculate Recall-based Weights \n",
        "\n",
        "try:\n",
        "    # Check if AAL results are available\n",
        "    aal_preds = np.array(all_aal_preds)\n",
        "    true_labels = np.array(all_aal_labels) \n",
        "    aal_probs = np.array(all_aal_probs)\n",
        "    print(\"âœ… AAL results variables found.\")\n",
        "except NameError:\n",
        "    print(\"--- !!! ERROR !!! ---\")\n",
        "    print(\"AAL results variables (`all_aal_preds`, `all_aal_labels`, `all_aal_probs`) not found.\")\n",
        "    print(\"Please ensure you have run the AAL CV cell (bIbT2iLxdvsy) successfully.\")\n",
        "    raise NameError(\"AAL results not found. Cannot perform ensemble.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    # Check if Schaefer results are available\n",
        "    schaefer_preds = np.array(all_schaefer_preds)\n",
        "    schaefer_probs = np.array(all_schaefer_probs)\n",
        "    print(\"âœ… Schaefer results variables found.\")\n",
        "except NameError:\n",
        "    print(\"--- !!! ERROR !!! ---\")\n",
        "    print(\"Schaefer results variables (`all_schaefer_preds`, `all_schaefer_labels`, `all_schaefer_probs`) not found.\")\n",
        "    print(\"Please ensure you have run the Schaefer CV cell (X5jV4037Xc4L) successfully.\")\n",
        "    raise NameError(\"Schaefer results not found. Cannot perform ensemble.\")\n",
        "\n",
        "\n",
        "# Determine weights for weighted sum using the formula: w_j = Recall_j / sum(Recall_i)\n",
        "try:\n",
        "    aal_avg_recall = np.mean([f['recall'] for f in aal_fold_history])\n",
        "    schaefer_avg_recall = np.mean([f['recall'] for f in schaefer_fold_history])\n",
        "\n",
        "    # Calculate total Recall sum\n",
        "    total_recall_sum = aal_avg_recall + schaefer_avg_recall\n",
        "\n",
        "    # Calculate weights using the formula w_j = Recall_j / sum(Recall_i)\n",
        "    if total_recall_sum > 0:\n",
        "        aal_weight = aal_avg_recall / total_recall_sum\n",
        "        schaefer_weight = schaefer_avg_recall / total_recall_sum\n",
        "    else:\n",
        "        print(\"Warning: Total Recall sum is zero. Using equal weights (0.5) for tie-breaking.\")\n",
        "        aal_weight = 0.5\n",
        "        schaefer_weight = 0.5\n",
        "\n",
        "    print(f\"Using Recall-based weights for tie-breaking: AAL={aal_weight:.4f}, Schaefer={schaefer_weight:.4f}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Warning: Could not access fold_history to get average Recalls for weighted sum calculation.\")\n",
        "    print(\"Using equal weights (0.5) for tie-breaking.\")\n",
        "    aal_weight = 0.5\n",
        "    schaefer_weight = 0.5\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Error calculating Recall-based weights: {e}\")\n",
        "    print(\"Using equal weights (0.5) for tie-breaking.\")\n",
        "    aal_weight = 0.5\n",
        "    schaefer_weight = 0.5\n",
        "\n",
        "\n",
        "# Perform Ensemble Prediction (Hard Voting with Recall Weighted Sum for Ties) \n",
        "\n",
        "def ensemble_predict_hard_weighted_tie(aal_preds, aal_probs, schaefer_preds, schaefer_probs, aal_weight, schaefer_weight):\n",
        "    \"\"\"\n",
        "    Performs Hard Voting ensemble with Recall-based Weighted Sum for ties.\n",
        "\n",
        "    Args:\n",
        "        aal_preds (np.ndarray): Predicted labels from AAL model (shape: num_samples)\n",
        "        aal_probs (np.ndarray): Predicted probabilities from AAL model (shape: num_samples, num_classes)\n",
        "        schaefer_preds (np.ndarray): Predicted labels from Schaefer model (shape: num_samples)\n",
        "        schaefer_probs (np.ndarray): Predicted probabilities from Schaefer model (shape: num_samples, num_classes)\n",
        "        aal_weight (float): Weight for AAL model in case of tie-breaking.\n",
        "        schaefer_weight (float): Weight for Schaefer model in case of tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Final ensemble predictions (shape: num_samples)\n",
        "    \"\"\"\n",
        "    num_samples = len(aal_preds)\n",
        "    ensemble_preds = np.zeros(num_samples, dtype=int)\n",
        "\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        pred1 = aal_preds[i]\n",
        "        pred2 = schaefer_preds[i]\n",
        "\n",
        "        if pred1 == pred2:\n",
        "            # Both models agree on the prediction   \n",
        "            ensemble_preds[i] = pred1\n",
        "        else:\n",
        "            # Tie -> use weighted sum of probabilities based on Recall weights\n",
        "            weighted_probs = (aal_probs[i] * aal_weight) + (schaefer_probs[i] * schaefer_weight)\n",
        "\n",
        "            # Predict the class with the highest weighted probability\n",
        "            ensemble_preds[i] = np.argmax(weighted_probs)\n",
        "\n",
        "    return ensemble_preds\n",
        "\n",
        "\n",
        "print(\"\\n--- Performing Ensemble Prediction ---\")\n",
        "ensemble_predictions = ensemble_predict_hard_weighted_tie(aal_preds, aal_probs, schaefer_preds, schaefer_probs, aal_weight, schaefer_weight)\n",
        "\n",
        "\n",
        "# Evaluate Ensemble Performance \n",
        "print(\"\\n--- Evaluating Ensemble Performance ---\")\n",
        "\n",
        "ensemble_accuracy = accuracy_score(true_labels, ensemble_predictions)\n",
        "ensemble_f1 = f1_score(true_labels, ensemble_predictions, average='weighted')\n",
        "ensemble_cm = confusion_matrix(true_labels, ensemble_predictions)\n",
        "ensemble_classification_report_dict = classification_report(true_labels, ensemble_predictions, target_names=['CN', 'AD'], output_dict=True) \n",
        "\n",
        "# Extract and print individual metrics\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
        "print(f\"Ensemble F1-Score (weighted): {ensemble_f1:.4f}\")\n",
        "print(f\"Ensemble Precision (CN): {ensemble_classification_report_dict['CN']['precision']:.4f}\")\n",
        "print(f\"Ensemble Recall (CN): {ensemble_classification_report_dict['CN']['recall']:.4f}\")\n",
        "print(f\"Ensemble Precision (AD): {ensemble_classification_report_dict['AD']['precision']:.4f}\")\n",
        "print(f\"Ensemble Recall (AD): {ensemble_classification_report_dict['AD']['recall']:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nEnsemble Classification Report:\")\n",
        "print(classification_report(true_labels, ensemble_predictions, target_names=['CN', 'AD'], digits=4))\n",
        "\n",
        "# Visualize Ensemble Results \n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(ensemble_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "plt.title('Hard Voting + Tie Based on Recall Weighted Sum Confusion Matrix (AAL + Schaefer KNN Graphs)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "weighted_ensemble_probs_for_roc = (aal_probs * aal_weight) + (schaefer_probs * schaefer_weight)\n",
        "probs_positive_class_ensemble_for_roc = weighted_ensemble_probs_for_roc[:, 1]\n",
        "\n",
        "if len(true_labels) == len(probs_positive_class_ensemble_for_roc):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, probs_positive_class_ensemble_for_roc)\n",
        "    roc_auc_ensemble = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_ensemble:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Hard Voting + Tie Based on Recall Weighted Sum Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "else:\n",
        "     print(f\"Error: Length of true labels ({len(true_labels)}) does not match length of ensemble probabilities ({len(probs_positive_class_ensemble_for_roc)}). Cannot plot ROC curve.\")\n",
        "\n",
        "print(f\"Ensemble AUC: {roc_auc_ensemble:.4f}\") \n",
        "\n",
        "print(\"\\n--- Ensemble Analysis Complete ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
