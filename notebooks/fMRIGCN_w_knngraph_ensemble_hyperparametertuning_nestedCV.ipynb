{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcETEs3sciNg",
        "outputId": "c9ac8d7b-60f7-424a-befc-5367523635f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Library Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p3F7GLjJWqKE",
        "outputId": "87d133e2-e0e8-408f-c03b-bed8eed54c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt28cu126)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n",
            "▶︎ Successfully installed PyTorch 2.8.0 with CUDA cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "print(f'▶︎ Successfully installed PyTorch {TORCH} with CUDA {CUDA}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmlvXg84ZVGx",
        "outputId": "6523c0d3-a761-4c3d-a179-d505ed1e68dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶︎ Finished Environment Setting\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Dataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "print(\"▶︎ Finished Environment Setting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9vftGDAdBTh",
        "outputId": "d8ca66e3-0167-4750-9e9e-587954b6a401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-FK0QcBZYM1",
        "outputId": "b87ab7e9-c001-4f88-f67d-0f220f383a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶︎ Finished Drive Mount and Directory Settings.\n"
          ]
        }
      ],
      "source": [
        "# Schaefer Atlas\n",
        "CN_FC_SCHAEFER_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/CN_conn_roi_data/schaefer/fc')\n",
        "CN_ROI_SCHAEFER_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/CN_conn_roi_data/schaefer/roi')\n",
        "AD_FC_SCHAEFER_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/AD_conn_roi_data/schaefer/fc')\n",
        "AD_ROI_SCHAEFER_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/AD_conn_roi_data/schaefer/roi')\n",
        "\n",
        "# AAL Atlas\n",
        "CN_FC_AAL_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/CN_conn_roi_data/aal/fc')\n",
        "CN_ROI_AAL_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/CN_conn_roi_data/aal/roi')\n",
        "AD_FC_AAL_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/AD_conn_roi_data/aal/fc')\n",
        "AD_ROI_AAL_DIR = Path('/content/drive/MyDrive/AD_fMRI_GNN/AD_conn_roi_data/aal/roi')\n",
        "\n",
        "\n",
        "# Hyperparameters \n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 32\n",
        "INNER_NUM_EPOCHS = 30\n",
        "OUTER_NUM_EPOCHS = 100\n",
        "DROPOUT_RATE = 0.5\n",
        "\n",
        "print(\"▶︎ Finished Drive Mount and Directory Settings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc3e4539"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "\n",
        "class fMRIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Processing fMRI Dataset for single Atlas (AAL or Schaefer) using KNN graph.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root, cn_fc_dir, cn_roi_dir, ad_fc_dir, ad_roi_dir, k_neighbors=10, transform=None, pre_transform=None):\n",
        "        self.cn_fc_dir = cn_fc_dir\n",
        "        self.cn_roi_dir = cn_roi_dir\n",
        "        self.ad_fc_dir = ad_fc_dir\n",
        "        self.ad_roi_dir = ad_roi_dir\n",
        "        self.k_neighbors = k_neighbors \n",
        "\n",
        "        # Determine atlas_type based on directory names\n",
        "        if 'schaefer' in str(cn_fc_dir).lower():\n",
        "            self.atlas_type = 'schaefer'\n",
        "        elif 'aal' in str(cn_fc_dir).lower():\n",
        "            self.atlas_type = 'aal'\n",
        "        else:\n",
        "            self.atlas_type = 'unknown'\n",
        "            print(f\"Warning: Could not determine atlas type from directory names: {cn_fc_dir}\")\n",
        "\n",
        "\n",
        "        self.ad_subjects = [f.stem.split('_')[0] for f in self.ad_fc_dir.glob('*.csv')]\n",
        "        self.cn_subjects = [f.stem.split('_')[0] for f in self.cn_fc_dir.glob('*.csv')]\n",
        "        self.all_subjects = sorted(list(set(self.ad_subjects + self.cn_subjects)))\n",
        "\n",
        "        # Ensure all subjects have both FC and ROI files, otherwise exclude them.\n",
        "        valid_subjects = []\n",
        "        for sub in self.all_subjects:\n",
        "            expected_fc_path = (self.ad_fc_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_connectivity_matrix.csv\") if sub in self.ad_subjects else (self.cn_fc_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_connectivity_matrix.csv\")\n",
        "            expected_roi_path = (self.ad_roi_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_roi_timeseries.csv\") if sub in self.ad_subjects else (self.cn_roi_dir / f\"{sub}_task-rest_bold_{self.atlas_type}_roi_timeseries.csv\")\n",
        "\n",
        "            fc_found = expected_fc_path.exists() or list(self.ad_fc_dir.glob(f\"{sub}*connectivity_matrix.csv\")) or list(self.cn_fc_dir.glob(f\"{sub}*connectivity_matrix.csv\"))\n",
        "            roi_found = expected_roi_path.exists() or list(self.ad_roi_dir.glob(f\"{sub}*roi_timeseries.csv\")) or list(self.cn_roi_dir.glob(f\"{sub}*roi_timeseries.csv\"))\n",
        "\n",
        "\n",
        "            if fc_found and roi_found:\n",
        "                valid_subjects.append(sub)\n",
        "            else:\n",
        "                if not fc_found and not roi_found:\n",
        "                    print(f\"Warning: FC and ROI data missing for subject {sub}. Skipping.\")\n",
        "                elif not fc_found:\n",
        "                    print(f\"Warning: FC data missing for subject {sub}. Skipping.\")\n",
        "                elif not roi_found:\n",
        "                     print(f\"Warning: ROI data missing for subject {sub}. Skipping.\")\n",
        "\n",
        "\n",
        "        self.all_subjects = valid_subjects\n",
        "        self.ad_subjects = [sub for sub in self.all_subjects if sub in self.ad_subjects]\n",
        "        self.cn_subjects = [sub for sub in self.all_subjects if sub in self.cn_subjects]\n",
        "\n",
        "        print(f\"Initialized dataset with {len(self.all_subjects)} valid subjects.\")\n",
        "\n",
        "\n",
        "        super(fMRIDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "         # This method is typically for raw files that need processing.\n",
        "         cn_files = [f.name for f in self.cn_fc_dir.glob('*.csv')] + [f.name for f in self.cn_roi_dir.glob('*.csv')]\n",
        "         ad_files = [f.name for f in self.ad_fc_dir.glob('*.csv')] + [f.name for f in self.ad_roi_dir.glob('*.csv')]\n",
        "         return list(set(cn_files + ad_files)) # Return unique file names\n",
        "\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # Define the names of the processed data files\n",
        "        return [f'data_{i}.pt' for i in range(len(self.all_subjects))]\n",
        "\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        # Process raw data into PyTorch Geometric Data objects\n",
        "        print(f\"Processing {len(self.all_subjects)} subjects...\")\n",
        "        for idx, subject_id in enumerate(self.all_subjects):\n",
        "            print(f\"Processing subject {subject_id} ({idx + 1}/{len(self.all_subjects)})...\")\n",
        "\n",
        "            # Determine file paths based on subject group and stored atlas type\n",
        "            if subject_id in self.ad_subjects:\n",
        "                label = 1\n",
        "                fc_dir, roi_dir = self.ad_fc_dir, self.ad_roi_dir\n",
        "            else:\n",
        "                label = 0\n",
        "                fc_dir, roi_dir = self.cn_fc_dir, self.cn_roi_dir\n",
        "\n",
        "            fc_path_candidates = list(fc_dir.glob(f\"{subject_id}*connectivity_matrix.csv\"))\n",
        "            roi_path_candidates = list(roi_dir.glob(f\"{subject_id}*roi_timeseries.csv\"))\n",
        "\n",
        "            fc_path = fc_path_candidates[0] if fc_path_candidates else None\n",
        "            roi_path = roi_path_candidates[0] if roi_path_candidates else None\n",
        "\n",
        "\n",
        "            if fc_path is None or roi_path is None:\n",
        "                 print(f\"Error during processing: Data for subject {subject_id} not found at expected paths. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            try:\n",
        "                fc_matrix = pd.read_csv(fc_path, index_col=0).values\n",
        "                roi_data = pd.read_csv(roi_path).values\n",
        "                print(f\"  Successfully loaded data. FC shape: {fc_matrix.shape}, ROI shape: {roi_data.shape}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading files for subject {subject_id}: {e}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Robust ROI Data Transposition Logic \n",
        "            initial_roi_shape = roi_data.shape\n",
        "            expected_nodes = fc_matrix.shape[0]\n",
        "\n",
        "            if initial_roi_shape[0] == expected_nodes:\n",
        "                pass\n",
        "            elif initial_roi_shape[1] == expected_nodes:\n",
        "                roi_data = roi_data.T\n",
        "                print(f\"  Transposed ROI data for subject {subject_id}. Initial shape: {initial_roi_shape}, New shape: {roi_data.shape}\")\n",
        "            else:\n",
        "                print(f\"Warning: ROI data shape mismatch for subject {subject_id}. Expected one dimension to match number of nodes ({expected_nodes}), got shape {initial_roi_shape}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            if roi_data.shape[0] != expected_nodes:\n",
        "                 print(f\"Error: ROI data first dimension still does not match expected nodes after transposition logic for subject {subject_id}. Expected {expected_nodes}, got {roi_data.shape[0]}. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            # Define Node Features \n",
        "            # Use the rows of the FC matrix as node features\n",
        "            x = torch.tensor(fc_matrix, dtype=torch.float)\n",
        "            num_nodes = x.shape[0]\n",
        "            print(f\"  Node features (x) shape: {x.shape}\")\n",
        "\n",
        "            # Implement KNN Graph Construction and Edge Weighting \n",
        "            edge_index = []\n",
        "            edge_attr = []\n",
        "\n",
        "            # Nearest Neighbours with Eusclidean distance\n",
        "            nn = NearestNeighbors(n_neighbors=self.k_neighbors + 1, metric='euclidean') # +1 to exclude self\n",
        "            nn.fit(x.cpu().numpy()) # Fit on CPU numpy array\n",
        "\n",
        "            # Find neighbors and distances\n",
        "            distances, indices = nn.kneighbors(x.cpu().numpy())\n",
        "\n",
        "            for i in range(num_nodes):\n",
        "                # Connect node i to its k_neighbors (excluding itself)\n",
        "                for j in range(1, self.k_neighbors + 1):\n",
        "                    neighbor_index = indices[i, j]\n",
        "                    distance = distances[i, j]\n",
        "\n",
        "                    # Add directed edge \n",
        "                    edge_index.append([i, neighbor_index])\n",
        "\n",
        "                    weight = 1.0 / (distance + 1e-8)\n",
        "                    edge_attr.append([weight])\n",
        "\n",
        "\n",
        "            # Convert lists to tensors\n",
        "            if not edge_index: # Handle case with no edges (e.g., k=0 or issues)\n",
        "                edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "                edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
        "            else:\n",
        "                edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "                edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "            # Ensure edge_index has correct shape (2, num_edges)\n",
        "            if edge_index.ndim != 2 or edge_index.shape[0] != 2:\n",
        "                 print(f\"Error creating edge_index for subject {subject_id}. Skipping.\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            # PyTorch Geometric Data object\n",
        "            data = Data(x=x,\n",
        "                        edge_index=edge_index,\n",
        "                        edge_attr=edge_attr, # Add edge attributes\n",
        "                        y=torch.tensor([label], dtype=torch.long))\n",
        "\n",
        "            # Save the processed data object\n",
        "            save_path = os.path.join(self.processed_dir, f'data_{idx}.pt')\n",
        "            try:\n",
        "                torch.save(data, save_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving processed data for subject {subject_id} to {save_path}: {e}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "        print(\"Finished processing subjects.\")\n",
        "\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'), weights_only=False)\n",
        "        return data\n",
        "\n",
        "    def len(self) -> int:\n",
        "        \"\"\"Returns the number of data objects stored in the dataset.\"\"\"\n",
        "        return len(self.all_subjects) \n",
        "\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self):\n",
        "        if len(self.processed_file_names) > 0:\n",
        "             try:\n",
        "                 first_processed_file = os.path.join(self.processed_dir, self.processed_file_names[0])\n",
        "                 if os.path.exists(first_processed_file):\n",
        "                     data = torch.load(first_processed_file, weights_only=False)\n",
        "\n",
        "                     return data.x.shape[1] \n",
        "                 else:\n",
        "                     print(f\"Warning: First processed file not found at {first_processed_file}. Cannot determine num_node_features.\")\n",
        "                     return 0\n",
        "             except Exception as e:\n",
        "                 print(f\"Error loading first processed file to determine num_node_features: {e}\")\n",
        "                 return 0\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsW2z5Qqt9-_",
        "outputId": "6ad624bb-b595-42e8-e051-26f077d1ef44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶︎ Finished Defining Dataset Class and GCN Model (Modified for weighted edges).\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data \n",
        "import torch\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes, hidden_channels=64):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin1 = Linear(hidden_channels, num_classes)\n",
        "        self.dropout = Dropout(p=DROPOUT_RATE)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Data object now contains edge_attr\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "\n",
        "        edge_weight = edge_attr.squeeze() if edge_attr is not None else None\n",
        "\n",
        "        x = self.conv1(x, edge_index, edge_weight) # Pass edge_weight\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight) # Pass edge_weight \n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Global pooling remains the same\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin1(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "print(\"▶︎ Finished Defining Dataset Class and GCN Model (Modified for weighted edges).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AudyYJ12HAiz",
        "outputId": "2b910c34-7ce9-4f87-8686-7ba89bd7ed74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶︎ Finished Defining Training and Testing Function.\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score \n",
        "\n",
        "def train_model(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in tqdm(loader, desc=\"Training\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def test_model(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(data.y.cpu().numpy())\n",
        "            all_probs.extend(torch.exp(out).cpu().numpy())\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    \n",
        "    # Calculate AUC\n",
        "    auc_score = 0 \n",
        "    if len(np.unique(all_labels)) > 1 and np.array(all_probs).shape[1] == 2:\n",
        "        try:\n",
        "            probs_positive_class = np.array(all_probs)[:, 1]\n",
        "            auc_score = roc_auc_score(all_labels, probs_positive_class)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate AUC: {e}\")\n",
        "            auc_score = 0\n",
        "\n",
        "    # Calculate Recall for the positive class (AD, label 1)\n",
        "    recall = 0 \n",
        "    if len(all_labels) > 0 and 1 in all_labels:\n",
        "        try:\n",
        "            recall = recall_score(all_labels, all_preds, pos_label=1)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not calculate Recall: {e}\")\n",
        "            recall = 0\n",
        "\n",
        "\n",
        "    return accuracy, f1, auc_score, recall, all_preds, all_labels, np.array(all_probs)\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, title):\n",
        "    \"\"\"\n",
        "    Visualising Confusion Matrix\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()\n",
        "\n",
        "print(\"▶︎ Finished Defining Training and Testing Function.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-mg1jgHP78",
        "outputId": "8a2bb2e8-c658-4430-f97a-63f4dfb87e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖥️ Current Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"🖥️ Current Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcXXJ1FYeKhb"
      },
      "outputs": [],
      "source": [
        "# Model Training \n",
        "def run_training(atlas_name, dataset, num_epochs=100):\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"▶︎ Start Training {atlas_name} Atlas Model ...\")\n",
        "\n",
        "    # Data Splitting\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        np.arange(len(dataset)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=[data.y.item() for data in dataset]\n",
        "    )\n",
        "    train_dataset = dataset[train_idx]\n",
        "    test_dataset = dataset[test_idx]\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialise Model ->  Optimiser, Loss function\n",
        "    model = GCN(\n",
        "        num_node_features=dataset.num_node_features,\n",
        "        num_classes=dataset.num_classes,\n",
        "        hidden_channels=64\n",
        "    ).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training the model\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        loss = train_model(model, train_loader, criterion, optimizer, device)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    # Evaluating the model\n",
        "    test_acc, test_f1, test_auc, test_recall, _, _, _ = test_model(model, test_loader, device) # Capture all returned metrics\n",
        "    print(f\"{atlas_name} Model Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test F1-Score: {test_f1:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test AUC: {test_auc:.4f}\")\n",
        "    print(f\"{atlas_name} Model Test Recall (AD): {test_recall:.4f}\")\n",
        "\n",
        "\n",
        "    # Saving the trained model\n",
        "    model_save_path = f'./{atlas_name}_gcn_model.pth'\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"{atlas_name} model is save in the path: '{model_save_path}'.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return model, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAVCB1vc2bCA"
      },
      "source": [
        "#Recall을 기준으로 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d5562a3",
        "outputId": "f992ce31-91f6-4110-9472-ebcb370c9c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶︎ Defined hyperparameters:\n",
            "{'learning_rate': [0.01, 0.005, 0.001], 'dropout_rate': [0.3, 0.5, 0.7], 'hidden_channels': [32, 64, 128], 'k_neighbors': [5, 10, 15]}\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter candidates for Random Search\n",
        "params = {\n",
        "    'learning_rate': [0.01, 0.005, 0.001],\n",
        "    'dropout_rate': [0.3, 0.5, 0.7],\n",
        "    'hidden_channels': [32, 64, 128],\n",
        "    'k_neighbors': [5, 10, 15]\n",
        "}\n",
        "\n",
        "print(\"▶︎ Defined hyperparameters:\")\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AAL Model Training Using Hyperparameter Tuning with Nested CV\n",
        "- Nested Cross-validation for the single model\n",
        "- do Random Search within each outer fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fpTWM26NsA04",
        "outputId": "85973c98-f12e-485f-b888-756810904cfe"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, roc_curve, auc, roc_auc_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import random \n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting AAL Model Nested Cross-Validation with KNN Graph and Random Search Tuning\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Cross-Validation & Hyperparameter Setup \n",
        "OUTER_K_FOLDS = 10\n",
        "INNER_K_FOLDS = 5\n",
        "N_RANDOM = 20 \n",
        "\n",
        "\n",
        "# Generate Random Hyperparameter Combinations \n",
        "all_combinations = list(itertools.product(*params.values()))\n",
        "num_to_sample = min(N_RANDOM, len(all_combinations))\n",
        "random_combinations_tuples = random.sample(all_combinations, k=num_to_sample)\n",
        "# Convert tuples to dictionaries\n",
        "random_combinations = [dict(zip(params.keys(), combo)) for combo in random_combinations_tuples]\n",
        "print(f\"Total possible hyperparameter combinations: {len(all_combinations)}\")\n",
        "print(f\"Testing {len(random_combinations)} random combinations in each outer fold.\")\n",
        "\n",
        "\n",
        "# Cross-Validation Setup \n",
        "skf_outer = StratifiedKFold(n_splits=OUTER_K_FOLDS, shuffle=True, random_state=42)\n",
        "skf_inner = StratifiedKFold(n_splits=INNER_K_FOLDS, shuffle=True, random_state=84) # Inner CV uses a different seed\n",
        "\n",
        "# Lists to store results for each Outer Fold\n",
        "aal_outer_fold_history = []\n",
        "all_aal_preds = []\n",
        "all_aal_labels = []\n",
        "all_aal_probs = []\n",
        "\n",
        "# Load Full Dataset Info for subject list and labels \n",
        "full_dataset_aal_info = fMRIDataset(\n",
        "    root='./data/aal_full_cv_info_tuning',\n",
        "    cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "    ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "    k_neighbors=10\n",
        ")\n",
        "dataset_labels = [data.y.item() for data in full_dataset_aal_info]\n",
        "full_subject_list = full_dataset_aal_info.all_subjects\n",
        "\n",
        "\n",
        "# Start Outer Cross-Validation Loop \n",
        "for outer_fold, (train_idx_outer, test_idx_outer) in enumerate(skf_outer.split(np.arange(len(full_subject_list)), dataset_labels)):\n",
        "    print(f\"\\n=============== OUTER FOLD {outer_fold+1}/{OUTER_K_FOLDS} ================\")\n",
        "    print(\"\\n--- Starting Inner CV Loop for Hyperparameter Tuning ---\")\n",
        "\n",
        "    inner_tuning_results = [] # store the performance of each hyperparameter combination\n",
        "\n",
        "    for i, current_hyperparams in enumerate(random_combinations):\n",
        "        print(f\"\\n  Testing Hyperparams {i+1}/{len(random_combinations)}: {current_hyperparams}\")\n",
        "\n",
        "        # --- Inner Cross-Validation ---\n",
        "        inner_fold_recalls = [] # recall for each inner fold\n",
        "        current_k_neighbors = current_hyperparams['k_neighbors']\n",
        "\n",
        "        dataset_aal_inner_cv = fMRIDataset(\n",
        "             root=f'./data/aal_outer_{outer_fold+1}_inner_cv_k{current_k_neighbors}',\n",
        "             cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "             ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "             k_neighbors=current_k_neighbors\n",
        "        )\n",
        "\n",
        "        # labels for the outer training set for inner stratification\n",
        "        outer_train_labels = [dataset_labels[i] for i in train_idx_outer]\n",
        "\n",
        "        for inner_fold, (train_idx_inner, val_idx_inner) in enumerate(skf_inner.split(train_idx_outer, outer_train_labels)):\n",
        "    \n",
        "            actual_train_idx_inner = [train_idx_outer[i] for i in train_idx_inner]\n",
        "            actual_val_idx_inner = [train_idx_outer[i] for i in val_idx_inner]\n",
        "\n",
        "            # Subsets and DataLoaders for the inner fold\n",
        "            train_dataset_inner = torch.utils.data.Subset(dataset_aal_inner_cv, actual_train_idx_inner)\n",
        "            val_dataset_inner = torch.utils.data.Subset(dataset_aal_inner_cv, actual_val_idx_inner)\n",
        "            train_loader_inner = DataLoader(train_dataset_inner, batch_size=BATCH_SIZE, shuffle=True)\n",
        "            val_loader_inner = DataLoader(val_dataset_inner, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            # Initialise and Train Model for Inner Fold\n",
        "            model_inner = GCN(\n",
        "                num_node_features=dataset_aal_inner_cv.num_node_features,\n",
        "                num_classes=dataset_aal_inner_cv.num_classes,\n",
        "                hidden_channels=current_hyperparams['hidden_channels']\n",
        "            ).to(device)\n",
        "            optimizer_inner = torch.optim.Adam(model_inner.parameters(), lr=current_hyperparams['learning_rate'])\n",
        "            criterion_inner = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "            DROPOUT_RATE = current_hyperparams['dropout_rate']\n",
        "\n",
        "            for epoch_inner in range(1, INNER_NUM_EPOCHS + 1):\n",
        "                train_model(model_inner, train_loader_inner, criterion_inner, optimizer_inner, device)\n",
        "\n",
        "            # Evaluate on inner validation set and store recall\n",
        "            _, _, _, val_recall, _, _, _ = test_model(model_inner, val_loader_inner, device)\n",
        "            inner_fold_recalls.append(val_recall)\n",
        "\n",
        "            # Memory Cleanup for Inner Fold \n",
        "            del model_inner, optimizer_inner, criterion_inner\n",
        "            del train_dataset_inner, val_dataset_inner, train_loader_inner, val_loader_inner\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Calculate average recall across inner folds for the current hyperparameter set\n",
        "        avg_inner_recall = np.mean(inner_fold_recalls)\n",
        "        print(f\"  --> Avg. Inner CV Recall for these hyperparams: {avg_inner_recall:.4f}\")\n",
        "        inner_tuning_results.append({\n",
        "            'hyperparams': current_hyperparams,\n",
        "            'avg_recall': avg_inner_recall\n",
        "        })\n",
        "        # Cleanup dataset for this k_neighbors\n",
        "        del dataset_aal_inner_cv\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    # Find the best hyperparameters based on the highest average inner CV recall\n",
        "    best_performing_set = max(inner_tuning_results, key=lambda x: x['avg_recall'])\n",
        "    best_hyperparams = best_performing_set['hyperparams']\n",
        "    best_avg_recall = best_performing_set['avg_recall']\n",
        "\n",
        "    print(\"\\n--- Inner CV Complete. Best Hyperparameters for Outer Fold \"\n",
        "          f\"{outer_fold+1}: {best_hyperparams} (Avg. Inner Recall: {best_avg_recall:.4f}) ---\")\n",
        "\n",
        "    # Train Final Model on Outer Training Set with Best Hyperparameters \n",
        "    print(f\"\\nFold {outer_fold+1}: Training Final AAL Model with Best Hyperparameters...\")\n",
        "\n",
        "    # Extract best hyperparams \n",
        "    best_k_neighbors = best_hyperparams['k_neighbors']\n",
        "    best_hidden_channels = best_hyperparams['hidden_channels']\n",
        "    best_dropout_rate = best_hyperparams['dropout_rate']\n",
        "    best_learning_rate = best_hyperparams['learning_rate']\n",
        "\n",
        "    # datasets and dataloaders \n",
        "    dataset_aal_outer_train = fMRIDataset(\n",
        "        root=f'./data/aal_outer_fold_{outer_fold+1}_final_train_k{best_k_neighbors}',\n",
        "        cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "        ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "        k_neighbors=best_k_neighbors\n",
        "    )\n",
        "    train_dataset_outer = torch.utils.data.Subset(dataset_aal_outer_train, train_idx_outer)\n",
        "    train_loader_outer = DataLoader(train_dataset_outer, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    dataset_aal_outer_test = fMRIDataset(\n",
        "        root=f'./data/aal_outer_fold_{outer_fold+1}_final_test_k{best_k_neighbors}',\n",
        "        cn_fc_dir=CN_FC_AAL_DIR, cn_roi_dir=CN_ROI_AAL_DIR,\n",
        "        ad_fc_dir=AD_FC_AAL_DIR, ad_roi_dir=AD_ROI_AAL_DIR,\n",
        "        k_neighbors=best_k_neighbors\n",
        "    )\n",
        "    test_dataset_outer = torch.utils.data.Subset(dataset_aal_outer_test, test_idx_outer)\n",
        "    test_loader_outer = DataLoader(test_dataset_outer, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialise Final Model with Best Hyperparameters\n",
        "    model_final = GCN(\n",
        "        num_node_features=dataset_aal_outer_train.num_node_features,\n",
        "        num_classes=dataset_aal_outer_train.num_classes,\n",
        "        hidden_channels=best_hidden_channels\n",
        "    ).to(device)\n",
        "    optimizer_final = torch.optim.Adam(model_final.parameters(), lr=best_learning_rate)\n",
        "    criterion_final = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    DROPOUT_RATE = best_dropout_rate\n",
        "\n",
        "    # Train the final model on the full outer training set\n",
        "    for epoch_outer in range(1, OUTER_NUM_EPOCHS + 1):\n",
        "        loss_outer = train_model(model_final, train_loader_outer, criterion_final, optimizer_final, device)\n",
        "        if epoch_outer % 10 == 0:\n",
        "             print(f'  Outer Epoch: {epoch_outer:03d}, Train Loss: {loss_outer:.4f}')\n",
        "\n",
        "    # Evaluate Final Model on Outer Test Set \n",
        "    test_accuracy, test_f1, test_auc, test_recall, preds_aal_test, labels_aal_test, probs_aal_test = test_model(model_final, test_loader_outer, device)\n",
        "\n",
        "    # Store Outer Fold Results\n",
        "    aal_outer_fold_history.append({\n",
        "        'fold': outer_fold + 1,\n",
        "        'best_hyperparams': best_hyperparams,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'test_f1': test_f1,\n",
        "        'test_auc': test_auc,\n",
        "        'test_recall': test_recall\n",
        "    })\n",
        "    all_aal_preds.extend(preds_aal_test)\n",
        "    all_aal_labels.extend(labels_aal_test)\n",
        "    all_aal_probs.extend(probs_aal_test)\n",
        "\n",
        "    print(f\"Outer Fold {outer_fold+1} Test Accuracy: {test_accuracy:.4f}, AUC: {test_auc:.4f}, Recall (AD): {test_recall:.4f}\")\n",
        "\n",
        "    # Memory Cleanup for Outer Loop \n",
        "    del model_final, optimizer_final, criterion_final\n",
        "    del train_dataset_outer, test_dataset_outer, train_loader_outer, test_loader_outer\n",
        "    del dataset_aal_outer_train, dataset_aal_outer_test\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n=============== Outer Cross-Validation Complete ===============\")\n",
        "\n",
        "# Final Result Analysis\n",
        "if aal_outer_fold_history:\n",
        "    avg_acc = np.mean([f['test_accuracy'] for f in aal_outer_fold_history])\n",
        "    avg_auc = np.mean([f['test_auc'] for f in aal_outer_fold_history])\n",
        "    avg_recall = np.mean([f['test_recall'] for f in aal_outer_fold_history])\n",
        "    avg_f1 = np.mean([f['test_f1'] for f in aal_outer_fold_history])\n",
        "\n",
        "    print(f\"\\n{OUTER_K_FOLDS}-Fold Nested Cross-validation Result (AAL with KNN Graph and Random Search Tuning):\")\n",
        "    print(f\"  - Average Test Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"  - Average Test AUC: {avg_auc:.4f}\")\n",
        "    print(f\"  - Average Test Recall (AD): {avg_recall:.4f}\")\n",
        "    print(f\"  - Average Test F1-Score: {avg_f1:.4f}\")\n",
        "\n",
        "    # Overall Confusion Matrix\n",
        "    all_aal_labels_np = np.array(all_aal_labels)\n",
        "    all_aal_preds_np = np.array(all_aal_preds)\n",
        "    cm = confusion_matrix(all_aal_labels_np, all_aal_preds_np)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "    plt.title(f'{OUTER_K_FOLDS}-Fold Nested CV Confusion Matrix (AAL Tuned Model)')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "    # Overall Classification Report\n",
        "    print(\"\\nOverall Classification Report:\")\n",
        "    print(classification_report(all_aal_labels_np, all_aal_preds_np, target_names=['CN', 'AD'], digits=4))\n",
        "\n",
        "    # Overall ROC Curve\n",
        "    all_aal_probs_np = np.array(all_aal_probs)\n",
        "    if all_aal_probs_np.ndim > 1 and all_aal_probs_np.shape[1] > 1:\n",
        "         probs_positive_class = all_aal_probs_np[:, 1]\n",
        "         if len(all_aal_labels_np) == len(probs_positive_class):\n",
        "             fpr, tpr, thresholds = roc_curve(all_aal_labels_np, probs_positive_class)\n",
        "             roc_auc_overall = auc(fpr, tpr)\n",
        "\n",
        "             plt.figure(figsize=(8, 8))\n",
        "             plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (overall area = {roc_auc_overall:.4f})')\n",
        "             plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "             plt.xlim([0.0, 1.0])\n",
        "             plt.ylim([0.0, 1.05])\n",
        "             plt.xlabel('False Positive Rate')\n",
        "             plt.ylabel('True Positive Rate')\n",
        "             plt.title('Overall Receiver Operating Characteristic (ROC) Curve for AAL Tuned Model')\n",
        "             plt.legend(loc=\"lower right\")\n",
        "             plt.show()\n",
        "         else:\n",
        "             print(f\"Error: Length of overall labels ({len(all_aal_labels_np)}) does not match length of overall probabilities ({len(probs_positive_class)}). Cannot plot overall ROC curve.\")\n",
        "    else:\n",
        "         print(\"Warning: Unexpected shape for overall AAL probabilities. Cannot plot overall ROC curve.\")\n",
        "\n",
        "else:\n",
        "    print(\"Couldn't execute nested cross-validation with hyperparameter tuning.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" AAL Model Nested Cross-Validation with Hyperparameter Tuning Complete\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schaefer Model Training Using Hyperparameter Tuning with Nested CV\n",
        "- Nested Cross-validation for the single model\n",
        "- do Random Search within each outer fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0fX9RmNV3zgk",
        "outputId": "93ed6dd8-17e6-428a-ad85-aa4f47a3977a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, roc_curve, auc, roc_auc_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import random \n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting Schaefer Model Nested Cross-Validation with KNN Graph and Random Search Tuning\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Cross-Validation & Hyperparameter Setup \n",
        "OUTER_K_FOLDS = 10\n",
        "INNER_K_FOLDS = 5\n",
        "N_RANDOM = 20 \n",
        "\n",
        "\n",
        "# Random Hyperparameter Combinations \n",
        "\n",
        "all_combinations = list(itertools.product(*params.values()))\n",
        "num_to_sample = min(N_RANDOM, len(all_combinations))\n",
        "random_combinations_tuples = random.sample(all_combinations, k=num_to_sample)\n",
        "# Tuple to dictionary conversion\n",
        "random_combinations = [dict(zip(params.keys(), combo)) for combo in random_combinations_tuples]\n",
        "print(f\"Total possible hyperparameter combinations: {len(all_combinations)}\")\n",
        "print(f\"Testing {len(random_combinations)} random combinations in each outer fold.\")\n",
        "\n",
        "\n",
        "# Cross-Validation Setup \n",
        "skf_outer = StratifiedKFold(n_splits=OUTER_K_FOLDS, shuffle=True, random_state=42)\n",
        "skf_inner = StratifiedKFold(n_splits=INNER_K_FOLDS, shuffle=True, random_state=84) \n",
        "\n",
        "# Lists to store results for each Outer Fold\n",
        "schaefer_outer_fold_history = []\n",
        "all_schaefer_preds = []\n",
        "all_schaefer_labels = []\n",
        "all_schaefer_probs = []\n",
        "\n",
        "# Load Full Dataset Info for subject list and labels \n",
        "full_dataset_schaefer_info = fMRIDataset(\n",
        "    root='./data/schaefer_full_cv_info_tuning',\n",
        "    cn_fc_dir=CN_FC_SCHAEFER_DIR, cn_roi_dir=CN_ROI_SCHAEFER_DIR,\n",
        "    ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "    k_neighbors=10\n",
        ")\n",
        "dataset_labels = [data.y.item() for data in full_dataset_schaefer_info]\n",
        "full_subject_list = full_dataset_schaefer_info.all_subjects\n",
        "\n",
        "\n",
        "# Outer Cross-Validation Loop \n",
        "for outer_fold, (train_idx_outer, test_idx_outer) in enumerate(skf_outer.split(np.arange(len(full_subject_list)), dataset_labels)):\n",
        "    print(f\"\\n=============== OUTER FOLD {outer_fold+1}/{OUTER_K_FOLDS} ================\")\n",
        "    print(\"\\n--- Starting Inner CV Loop for Hyperparameter Tuning ---\")\n",
        "\n",
        "    inner_tuning_results = []  #hyperparmeter tuning results\n",
        "\n",
        "    # Inner Cross-Validation for Hyperparameter Tuning\n",
        "    for i, current_hyperparams in enumerate(random_combinations):\n",
        "        print(f\"\\n  Testing Hyperparams {i+1}/{len(random_combinations)}: {current_hyperparams}\")\n",
        "\n",
        "        inner_fold_recalls = [] # Store recall for each inner fold\n",
        "        current_k_neighbors = current_hyperparams['k_neighbors']\n",
        "        \n",
        "        dataset_schaefer_inner_cv = fMRIDataset(\n",
        "             root=f'./data/schaefer_outer_{outer_fold+1}_inner_cv_k{current_k_neighbors}',\n",
        "             cn_fc_dir=CN_FC_SCHAEFER_DIR, cn_roi_dir=CN_ROI_SCHAEFER_DIR,\n",
        "             ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "             k_neighbors=current_k_neighbors\n",
        "        )\n",
        "\n",
        "        outer_train_labels = [dataset_labels[i] for i in train_idx_outer]\n",
        "\n",
        "        for inner_fold, (train_idx_inner, val_idx_inner) in enumerate(skf_inner.split(train_idx_outer, outer_train_labels)):\n",
        "            # The indices from skf_inner are relative to train_idx_outer, so we map them back\n",
        "            actual_train_idx_inner = [train_idx_outer[i] for i in train_idx_inner]\n",
        "            actual_val_idx_inner = [train_idx_outer[i] for i in val_idx_inner]\n",
        "\n",
        "            # Subsets and DataLoaders for the inner fold\n",
        "            train_dataset_inner = torch.utils.data.Subset(dataset_schaefer_inner_cv, actual_train_idx_inner)\n",
        "            val_dataset_inner = torch.utils.data.Subset(dataset_schaefer_inner_cv, actual_val_idx_inner)\n",
        "            train_loader_inner = DataLoader(train_dataset_inner, batch_size=BATCH_SIZE, shuffle=True)\n",
        "            val_loader_inner = DataLoader(val_dataset_inner, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            # Initialise and Train Model for Inner Fold\n",
        "            model_inner = GCN(\n",
        "                num_node_features=dataset_schaefer_inner_cv.num_node_features,\n",
        "                num_classes=dataset_schaefer_inner_cv.num_classes,\n",
        "                hidden_channels=current_hyperparams['hidden_channels']\n",
        "            ).to(device)\n",
        "            optimizer_inner = torch.optim.Adam(model_inner.parameters(), lr=current_hyperparams['learning_rate'])\n",
        "            criterion_inner = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "            DROPOUT_RATE = current_hyperparams['dropout_rate']\n",
        "\n",
        "            for epoch_inner in range(1, INNER_NUM_EPOCHS + 1):\n",
        "                train_model(model_inner, train_loader_inner, criterion_inner, optimizer_inner, device)\n",
        "\n",
        "            # Evaluate on inner validation set and store recall\n",
        "            _, _, _, val_recall, _, _, _ = test_model(model_inner, val_loader_inner, device)\n",
        "            inner_fold_recalls.append(val_recall)\n",
        "\n",
        "            # Memory Cleanup for Inner Fold \n",
        "            del model_inner, optimizer_inner, criterion_inner\n",
        "            del train_dataset_inner, val_dataset_inner, train_loader_inner, val_loader_inner\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Calculate average recall across inner folds \n",
        "        avg_inner_recall = np.mean(inner_fold_recalls)\n",
        "        print(f\"  --> Avg. Inner CV Recall for these hyperparams: {avg_inner_recall:.4f}\")\n",
        "        inner_tuning_results.append({\n",
        "            'hyperparams': current_hyperparams,\n",
        "            'avg_recall': avg_inner_recall\n",
        "        })\n",
        "        # Cleanup dataset for this k_neighbors\n",
        "        del dataset_schaefer_inner_cv\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    # Find the best hyperparameters based on the highest average inner CV recall\n",
        "    best_performing_set = max(inner_tuning_results, key=lambda x: x['avg_recall'])\n",
        "    best_hyperparams = best_performing_set['hyperparams']\n",
        "    best_avg_recall = best_performing_set['avg_recall']\n",
        "\n",
        "    print(\"\\n--- Inner CV Complete. Best Hyperparameters for Outer Fold \"\n",
        "          f\"{outer_fold+1}: {best_hyperparams} (Avg. Inner Recall: {best_avg_recall:.4f}) ---\")\n",
        "\n",
        "    # Train Final Model on Outer Training Set with Best Hyperparameters \n",
        "    print(f\"\\nFold {outer_fold+1}: Training Final Schaefer Model with Best Hyperparameters...\")\n",
        "\n",
        "    # Extract best hyperparams \n",
        "    best_k_neighbors = best_hyperparams['k_neighbors']\n",
        "    best_hidden_channels = best_hyperparams['hidden_channels']\n",
        "    best_dropout_rate = best_hyperparams['dropout_rate']\n",
        "    best_learning_rate = best_hyperparams['learning_rate']\n",
        "\n",
        "    # Create datasets and dataloaders for the outer loop\n",
        "    dataset_schaefer_outer_train = fMRIDataset(\n",
        "        root=f'./data/schaefer_outer_fold_{outer_fold+1}_final_train_k{best_k_neighbors}',\n",
        "        cn_fc_dir=CN_FC_SCHAEFER_DIR, cn_roi_dir=CN_ROI_SCHAEFER_DIR,\n",
        "        ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "        k_neighbors=best_k_neighbors\n",
        "    )\n",
        "    train_dataset_outer = torch.utils.data.Subset(dataset_schaefer_outer_train, train_idx_outer)\n",
        "    train_loader_outer = DataLoader(train_dataset_outer, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    dataset_schaefer_outer_test = fMRIDataset(\n",
        "        root=f'./data/schaefer_outer_fold_{outer_fold+1}_final_test_k{best_k_neighbors}',\n",
        "        cn_fc_dir=CN_FC_SCHAEFER_DIR, cn_roi_dir=CN_ROI_SCHAEFER_DIR,\n",
        "        ad_fc_dir=AD_FC_SCHAEFER_DIR, ad_roi_dir=AD_ROI_SCHAEFER_DIR,\n",
        "        k_neighbors=best_k_neighbors\n",
        "    )\n",
        "    test_dataset_outer = torch.utils.data.Subset(dataset_schaefer_outer_test, test_idx_outer)\n",
        "    test_loader_outer = DataLoader(test_dataset_outer, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialise Final Model with Best Hyperparameters\n",
        "    model_final = GCN(\n",
        "        num_node_features=dataset_schaefer_outer_train.num_node_features,\n",
        "        num_classes=dataset_schaefer_outer_train.num_classes,\n",
        "        hidden_channels=best_hidden_channels\n",
        "    ).to(device)\n",
        "    optimizer_final = torch.optim.Adam(model_final.parameters(), lr=best_learning_rate)\n",
        "    criterion_final = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set the best dropout rate\n",
        "    DROPOUT_RATE = best_dropout_rate\n",
        "\n",
        "    # Train the final model on the full outer training set\n",
        "    for epoch_outer in range(1, OUTER_NUM_EPOCHS + 1):\n",
        "        loss_outer = train_model(model_final, train_loader_outer, criterion_final, optimizer_final, device)\n",
        "        if epoch_outer % 10 == 0:\n",
        "             print(f'  Outer Epoch: {epoch_outer:03d}, Train Loss: {loss_outer:.4f}')\n",
        "\n",
        "    # Evaluate the Perfomance of Final Model on Outer Test Set \n",
        "    test_accuracy, test_f1, test_auc, test_recall, preds_schaefer_test, labels_schaefer_test, probs_schaefer_test = test_model(model_final, test_loader_outer, device)\n",
        "\n",
        "    # Store Outer Fold Results\n",
        "    schaefer_outer_fold_history.append({\n",
        "        'fold': outer_fold + 1,\n",
        "        'best_hyperparams': best_hyperparams,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'test_f1': test_f1,\n",
        "        'test_auc': test_auc,\n",
        "        'test_recall': test_recall\n",
        "    })\n",
        "    all_schaefer_preds.extend(preds_schaefer_test)\n",
        "    all_schaefer_labels.extend(labels_schaefer_test)\n",
        "    all_schaefer_probs.extend(probs_schaefer_test)\n",
        "\n",
        "    print(f\"Outer Fold {outer_fold+1} Test Accuracy: {test_accuracy:.4f}, AUC: {test_auc:.4f}, Recall (AD): {test_recall:.4f}\")\n",
        "\n",
        "    #  Memory Cleanup for Outer Loop\n",
        "    del model_final, optimizer_final, criterion_final\n",
        "    del train_dataset_outer, test_dataset_outer, train_loader_outer, test_loader_outer\n",
        "    del dataset_schaefer_outer_train, dataset_schaefer_outer_test\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n=============== Outer Cross-Validation Complete ===============\")\n",
        "\n",
        "# Final Result Analysis \n",
        "if schaefer_outer_fold_history:\n",
        "    avg_acc = np.mean([f['test_accuracy'] for f in schaefer_outer_fold_history])\n",
        "    avg_auc = np.mean([f['test_auc'] for f in schaefer_outer_fold_history])\n",
        "    avg_recall = np.mean([f['test_recall'] for f in schaefer_outer_fold_history])\n",
        "    avg_f1 = np.mean([f['test_f1'] for f in schaefer_outer_fold_history])\n",
        "\n",
        "\n",
        "    print(f\"\\n{OUTER_K_FOLDS}-Fold Nested Cross-validation Result (SCHAEFER with KNN Graph and Random Search Tuning):\")\n",
        "    print(f\"  - Average Test Accuracy: {avg_acc:.4f}\")\n",
        "    print(f\"  - Average Test AUC: {avg_auc:.4f}\")\n",
        "    print(f\"  - Average Test Recall (AD): {avg_recall:.4f}\")\n",
        "    print(f\"  - Average Test F1-Score: {avg_f1:.4f}\")\n",
        "\n",
        "    # Overall Confusion Matrix\n",
        "    all_schaefer_labels_np = np.array(all_schaefer_labels)\n",
        "    all_schaefer_preds_np = np.array(all_schaefer_preds)\n",
        "    cm = confusion_matrix(all_schaefer_labels_np, all_schaefer_preds_np)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "    plt.title(f'{OUTER_K_FOLDS}-Fold Nested CV Confusion Matrix (Schaefer Tuned Model)')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "    # Overall Classification Report\n",
        "    print(\"\\nOverall Classification Report:\")\n",
        "    print(classification_report(all_schaefer_labels_np, all_schaefer_preds_np, target_names=['CN', 'AD'], digits=4))\n",
        "\n",
        "    # Overall ROC Curve\n",
        "    all_schaefer_probs_np = np.array(all_schaefer_probs)\n",
        "    if all_schaefer_probs_np.ndim > 1 and all_schaefer_probs_np.shape[1] > 1:\n",
        "         probs_positive_class = all_schaefer_probs_np[:, 1]\n",
        "         if len(all_schaefer_labels_np) == len(probs_positive_class):\n",
        "             fpr, tpr, thresholds = roc_curve(all_schaefer_labels_np, probs_positive_class)\n",
        "             roc_auc_overall = auc(fpr, tpr)\n",
        "\n",
        "             plt.figure(figsize=(8, 8))\n",
        "             plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (overall area = {roc_auc_overall:.4f})')\n",
        "             plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "             plt.xlim([0.0, 1.0])\n",
        "             plt.ylim([0.0, 1.05])\n",
        "             plt.xlabel('False Positive Rate')\n",
        "             plt.ylabel('True Positive Rate')\n",
        "             plt.title('Overall Receiver Operating Characteristic (ROC) Curve for Schaefer Tuned Model')\n",
        "             plt.legend(loc=\"lower right\")\n",
        "             plt.show()\n",
        "         else:\n",
        "             print(f\"Error: Length of overall labels ({len(all_schaefer_labels_np)}) does not match length of overall probabilities ({len(probs_positive_class)}). Cannot plot overall ROC curve.\")\n",
        "    else:\n",
        "         print(\"Warning: Unexpected shape for overall Schaefer probabilities. Cannot plot overall ROC curve.\")\n",
        "\n",
        "else:\n",
        "    print(\"Couldn't execute nested cross-validation with hyperparameter tuning.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Schaefer Model Nested Cross-Validation with Hyperparameter Tuning Complete\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hard Voting + Tie Based on Recall Weighted Sum Ensemble (with Hyperparameter Tuning)\n",
        "- Performing Hard Voting and Weighted Sum Ensemble \n",
        "- AAL and Schaefer model for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c953cb7b",
        "outputId": "bda743e3-4548-4f00-ef73-82dec338eaeb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" Starting Hard Voting + Tie Based on Recall Weighted Sum Ensemble (using Tuned Models)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# Load AAL and Schaefer results from the hyperparameter tuning CV\n",
        "\n",
        "try:\n",
        "    # AAL Tuning Results \n",
        "    aal_preds = np.array(all_aal_preds)\n",
        "    true_labels = np.array(all_aal_labels) \n",
        "    aal_probs = np.array(all_aal_probs)\n",
        "    print(\"✅ Tuned AAL results variables found.\")\n",
        "except NameError:\n",
        "    print(\"--- !!! ERROR !!! ---\")\n",
        "    print(\"Tuned AAL results variables (`all_aal_preds`, `all_aal_labels`, `all_aal_probs`) not found.\")\n",
        "    print(\"Please ensure you have run the AAL CV with Hyperparameter Tuning cell successfully.\")\n",
        "    raise NameError(\"Tuned AAL results not found. Cannot perform ensemble.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    # Schaefer Tuning Results\n",
        "    schaefer_preds = np.array(all_schaefer_preds)\n",
        "    schaefer_probs = np.array(all_schaefer_probs)\n",
        "    print(\"✅ Tuned Schaefer results variables found.\")\n",
        "except NameError:\n",
        "    print(\"--- !!! ERROR !!! ---\")\n",
        "    print(\"Tuned Schaefer results variables (`all_schaefer_preds`, `all_schaefer_labels`, `all_schaefer_probs`) not found.\")\n",
        "    print(\"Please ensure you have run the Schaefer CV with Hyperparameter Tuning cell successfully.\")\n",
        "    raise NameError(\"Tuned Schaefer results not found. Cannot perform ensemble.\")\n",
        "\n",
        "# Evaluate the outer fold history to calculate average Recall for each model\n",
        "try:\n",
        "    # Compute average Recall for AAL and Schaefer models\n",
        "    aal_avg_recall = np.mean([f['test_recall'] for f in aal_outer_fold_history])\n",
        "    schaefer_avg_recall = np.mean([f['test_recall'] for f in schaefer_outer_fold_history])\n",
        "\n",
        "    # Total Recall sum for weighted average calculation\n",
        "    total_recall_sum = aal_avg_recall + schaefer_avg_recall\n",
        "\n",
        "    # Weight Calculation : w_j = Recall_j / sum(Recall_i)\n",
        "    if total_recall_sum > 0:\n",
        "        aal_weight = aal_avg_recall / total_recall_sum\n",
        "        schaefer_weight = schaefer_avg_recall / total_recall_sum\n",
        "    else:\n",
        "        print(\"Warning: Total average Recall sum is zero. Using equal weights (0.5) for tie-breaking.\")\n",
        "        aal_weight = 0.5\n",
        "        schaefer_weight = 0.5\n",
        "\n",
        "    print(f\"Using Average Recall-based weights for tie-breaking: AAL={aal_weight:.4f}, Schaefer={schaefer_weight:.4f}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Warning: Could not access outer_fold_history to get average Recalls for weighted sum calculation.\")\n",
        "    print(\"Using equal weights (0.5) for tie-breaking.\")\n",
        "    aal_weight = 0.5\n",
        "    schaefer_weight = 0.5\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Error calculating Average Recall-based weights: {e}\")\n",
        "    print(\"Using equal weights (0.5) for tie-breaking.\")\n",
        "    aal_weight = 0.5\n",
        "    schaefer_weight = 0.5\n",
        "\n",
        "\n",
        "# Ensemble Prediction (Hard Voting with Recall Weighted Sum for Ties) \n",
        "\n",
        "def ensemble_predict_hard_weighted_tie(aal_preds, aal_probs, schaefer_preds, schaefer_probs, aal_weight, schaefer_weight):\n",
        "    \"\"\"\n",
        "    Hard Voting 기반 앙상블을 수행하며, 동점일 경우 Recall 가중합으로 최종 예측을 결정합니다.\n",
        "    \"\"\"\n",
        "    num_samples = len(aal_preds)\n",
        "    ensemble_preds = np.zeros(num_samples, dtype=int)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        pred1 = aal_preds[i]\n",
        "        pred2 = schaefer_preds[i]\n",
        "\n",
        "        if pred1 == pred2:\n",
        "            # Hard Voting  \n",
        "            ensemble_preds[i] = pred1\n",
        "        else:\n",
        "            # Tie -> use weighted sum of recall-based probabilities\n",
        "            weighted_probs = (aal_probs[i] * aal_weight) + (schaefer_probs[i] * schaefer_weight)\n",
        "            ensemble_preds[i] = np.argmax(weighted_probs)\n",
        "\n",
        "    return ensemble_preds\n",
        "\n",
        "\n",
        "print(\"\\n--- Performing Ensemble Prediction ---\")\n",
        "ensemble_predictions = ensemble_predict_hard_weighted_tie(aal_preds, aal_probs, schaefer_preds, schaefer_probs, aal_weight, schaefer_weight)\n",
        "\n",
        "\n",
        "# Ensemble Model Performance Evaluation\n",
        "print(\"\\n--- Evaluating Ensemble Performance ---\")\n",
        "\n",
        "ensemble_accuracy = accuracy_score(true_labels, ensemble_predictions)\n",
        "ensemble_f1 = f1_score(true_labels, ensemble_predictions, average='weighted')\n",
        "ensemble_cm = confusion_matrix(true_labels, ensemble_predictions)\n",
        "ensemble_classification_report_str = classification_report(true_labels, ensemble_predictions, target_names=['CN', 'AD'], digits=4)\n",
        "ensemble_classification_report_dict = classification_report(true_labels, ensemble_predictions, target_names=['CN', 'AD'], output_dict=True)\n",
        "\n",
        "# Print Evaluation Results\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
        "print(f\"Ensemble F1-Score (weighted): {ensemble_f1:.4f}\")\n",
        "print(f\"Ensemble Recall (AD): {ensemble_classification_report_dict['AD']['recall']:.4f}\")\n",
        "\n",
        "print(\"\\nEnsemble Classification Report:\")\n",
        "print(ensemble_classification_report_str)\n",
        "\n",
        "\n",
        "\n",
        "# Ensemble Model Results Visualization\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(ensemble_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CN', 'AD'], yticklabels=['CN', 'AD'])\n",
        "plt.title('Hard Voting + Tie Based on Recall Weighted Sum Confusion Matrix (AAL + Schaefer Tuned Models)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "weighted_ensemble_probs_for_roc = (aal_probs * aal_weight) + (schaefer_probs * schaefer_weight)\n",
        "probs_positive_class_ensemble_for_roc = weighted_ensemble_probs_for_roc[:, 1]\n",
        "\n",
        "\n",
        "if len(true_labels) == len(probs_positive_class_ensemble_for_roc):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, probs_positive_class_ensemble_for_roc)\n",
        "    roc_auc_ensemble = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_ensemble:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Hard Voting + Tie Based on Recall Weighted Sum ROC Curve (Tuned Models)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Ensemble AUC: {roc_auc_ensemble:.4f}\")\n",
        "else:\n",
        "     print(f\"Error: Length of true labels ({len(true_labels)}) does not match length of ensemble probabilities ({len(probs_positive_class_ensemble_for_roc)}). Cannot plot ROC curve.\")\n",
        "\n",
        "print(\"\\n--- Ensemble Analysis Complete ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AD_fMRI_GNN",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
